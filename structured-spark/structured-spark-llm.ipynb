{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db1de9a-2561-4bfc-9846-93c076256a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta import *\n",
    "from chunkipy import TextChunker, TokenEstimator\n",
    "from numpy import exp\n",
    "import boto3\n",
    "import builtins\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581bfd20-b3f9-4432-8320-75d13cafa986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-14 16:56:21.747720: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 16:56:21.747776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 16:56:21.749187: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 16:56:21.757007: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 16:56:22.568464: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer, pipeline\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", framework=\"pt\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32694141-0f90-432c-9d82-5e82d922a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-d72b815e-a630-4255-88c4-7b93d3ed7f33;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in local-m2-cache\n",
      "\tfound io.delta#delta-storage;3.1.0 in local-m2-cache\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in local-m2-cache\n",
      ":: resolution report :: resolve 138ms :: artifacts dl 6ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from local-m2-cache in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from local-m2-cache in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-d72b815e-a630-4255-88c4-7b93d3ed7f33\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "24/03/14 16:56:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder.appName(\"amzn-reviews\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\",\"28g\") \\\n",
    "    .config(\"spark.executor.cores\",\"5\") \\\n",
    "    .config(\"spark.executor.instances\",\"2\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\",True) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", True) \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", False) \\\n",
    "    .config(\"spark.hadoop.parquet.enable.summary-metadata\", False) \\\n",
    "    .enableHiveSupport()\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425863ee-7725-4656-91cf-90217810897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get secrets credential for S3a\n",
    "REGION = \"us-east-1\"\n",
    "client = boto3.client('secretsmanager',region_name=REGION)\n",
    "response = client.get_secret_value(\n",
    "    SecretId='s3all'\n",
    ")\n",
    "accessJson = json.loads(response['SecretString'])\n",
    "accessKeyId = accessJson['accessKey']\n",
    "secretAccessKey = accessJson['secretAccess']\n",
    "\n",
    "# Configure S3a\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", accessKeyId)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secretAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532fa52b-cd78-4a03-8b39-2462b026bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenEstimator(TokenEstimator):\n",
    "    def __init__(self):\n",
    "        self.bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def estimate_tokens(self, text):\n",
    "        return len(self.bert_tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539f06db-c456-40b5-ba96-7ae0fee0eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkS3PrefixExist(bucket,prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    prefix_exist = \"\"\n",
    "    \n",
    "    try:\n",
    "        resp = s3.head_object(Bucket=bucket, Key=prefix)\n",
    "        prefix_exist = \"y\"\n",
    "    except s3.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            prefix_exist = \"n\"\n",
    "        else:\n",
    "            prefix_exist = \"something else\"\n",
    "\n",
    "    return prefix_exist\n",
    "\n",
    "def createS3Prefix(bucket,prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket,Key=prefix)\n",
    "\n",
    "def createDeltaSummarizedTable(path):\n",
    "    DeltaTable.createOrReplace(spark) \\\n",
    "     .addColumn(\"asin_key\", \"INT\") \\\n",
    "     .addColumn(\"reviewText\", \"STRING\") \\\n",
    "     .addColumn(\"bartUpdated\", \"STRING\") \\\n",
    "     .addColumn(\"sentimentAnalyzed\", \"STRING\") \\\n",
    "     .addColumn(\"sentiment\", \"STRING\")\\\n",
    "     .addColumn(\"bartSummary\", \"STRING\") \\\n",
    "     .location(path) \\\n",
    "     .execute()\n",
    "\n",
    "\n",
    "# calculate the softmax of a vector\n",
    "def softmax(vector):\n",
    " e = exp(vector)\n",
    " return e / e.sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51553b2-61bc-4a04-a29e-2a82b7fefd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPdfLLM(df):\n",
    "    # Variables\n",
    "    max_token_input = 1024\n",
    "    min_token_output = 130\n",
    "    chunk_size = 512\n",
    "    min_token_size = 200\n",
    "    \n",
    "    # Initializing summary to return\n",
    "    summary_text = \"\"\n",
    "    \n",
    "    # Initialize BertEstimator\n",
    "    bert_token_estimator = BertTokenEstimator()\n",
    "\n",
    "    # Initialize Classifier\n",
    "    classifier = pipeline(\n",
    "        task=\"zero-shot-classification\",\n",
    "        device=0,\n",
    "        model=\"facebook/bart-large-mnli\"\n",
    "    )\n",
    "\n",
    "    classifier_labels = ['negative', 'positive', 'neutral']\n",
    "\n",
    "    def batchSize(token_count, max_token_input):\n",
    "        quotient = token_count / max_token_input\n",
    "        remainder = token_count % max_token_input\n",
    "        return math.floor(quotient), remainder\n",
    "\n",
    "    def chunk(txt):\n",
    "        token_count = bert_token_estimator.estimate_tokens(txt)\n",
    "        text_chunker = TextChunker(chunk_size, tokens=True, token_estimator=BertTokenEstimator())\n",
    "        chunks = text_chunker.chunk(txt)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            yield chunk\n",
    "\n",
    "    def sentiment_func(result):\n",
    "#        result = classifier(txt,classifier_labels,multi_label=True)\n",
    "        labels = result[\"labels\"]\n",
    "        score = result[\"scores\"]\n",
    "        result_dict = {labels[i]: score[i] for i in range(len(labels))}\n",
    "\n",
    "        # builtins required so as not to confuse with pyspark max() function\n",
    "        sentiment = builtins.max(result_dict, key=result_dict.get)\n",
    "\n",
    "        return sentiment\n",
    "\n",
    "    def summarizer_func(corpus):\n",
    "        summary_response = summarizer(corpus, max_length=130, min_length=30, do_sample=False)\n",
    "        summary = summary_response[0][\"summary_text\"]\n",
    "        return summary\n",
    "        \n",
    "    # Main code\n",
    "    bartUpdated_list = []\n",
    "    sentimentAnalyzed_list = []\n",
    "    sentiment_list = []\n",
    "    bartSummary_list = []\n",
    "    reviewText = [d.reviewText for idx, d in df.iterrows()]\n",
    "    \n",
    "    for r in reviewText:\n",
    " \n",
    "        token_count = bert_token_estimator.estimate_tokens(r)\n",
    "\n",
    "        if token_count > max_token_input:\n",
    "\n",
    "            # Sentiment chunking\n",
    "\n",
    "            text_chunker = TextChunker(chunk_size, tokens=True, token_estimator=BertTokenEstimator())\n",
    "            chunks = text_chunker.chunk(r)\n",
    "\n",
    "            sentiment_results_list = []\n",
    "\n",
    "            sum_positive = 0\n",
    "            sum_negative = 0\n",
    "            sum_neutral = 0\n",
    "\n",
    "            corpus_chunks = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "\n",
    "                # Sentiment\n",
    "                result = classifier(chunk,classifier_labels,multi_label=True)\n",
    "                each_label = result[\"labels\"]\n",
    "                each_score = result[\"scores\"]\n",
    "\n",
    "                labels_positive_index = each_label.index(\"positive\")\n",
    "                labels_negative_index = each_label.index(\"negative\")\n",
    "                labels_neutral_index = each_label.index(\"neutral\")\n",
    "\n",
    "                sum_negative = sum_negative + result[\"scores\"][labels_negative_index]\n",
    "                sum_positive = sum_positive + result[\"scores\"][labels_positive_index]\n",
    "                sum_neutral = sum_neutral + result[\"scores\"][labels_neutral_index]\n",
    "\n",
    "                sentiment_results_list.append(each_score)\n",
    "\n",
    "                # Summarization\n",
    "                if bert_token_estimator.estimate_tokens(chunk)  <= min_token_size:\n",
    "                    corpus_chunks.append(chunk)\n",
    "                else:\n",
    "                    corpus_chunks.append(summarizer_func(chunk))\n",
    "            \n",
    "            # Sentiment\n",
    "            average_negative = sum_negative / i\n",
    "            average_positive = sum_positive / i\n",
    "            average_neutral = sum_neutral / i\n",
    "\n",
    "            score = []\n",
    "            score.append(average_negative)\n",
    "            score.append(average_positive)\n",
    "            score.append(average_neutral)\n",
    "\n",
    "            result_dict = {classifier_labels[i]: score[i] for i in range(len(classifier_labels))}\n",
    "\n",
    "            # builtins required so as not to confuse with pyspark max() function\n",
    "            sentiment_label = builtins.max(result_dict, key=result_dict.get)\n",
    "\n",
    "\n",
    "            # Summarization\n",
    "            s = \" \"\n",
    "            summary_text = s.join(corpus_chunks)\n",
    "        \n",
    "        else:\n",
    "            # Sentiment\n",
    "            result = classifier(r,classifier_labels,multi_label=True)\n",
    "            sentiment_label = sentiment_func(result)\n",
    "\n",
    "            # Summarization\n",
    "            if token_count < min_token_output:\n",
    "                summary_text = r\n",
    "            else:\n",
    "                summary_text = summarizer_func(r)\n",
    "\n",
    "        bartUpdated_list.append(\"Y\")\n",
    "        sentimentAnalyzed_list.append(\"Y\")\n",
    "        sentiment_list.append(sentiment_label)\n",
    "        bartSummary_list.append(summary_text)\n",
    "        #print(\"bartsummarylist:\", bartSummary_list)\n",
    "    \n",
    "    bartUpdated_array = np.array([bartUpdated_list])\n",
    "    bartUpdated_concat = np.concatenate(bartUpdated_array)\n",
    "\n",
    "    sentimentAnalyzed_array = np.array([sentimentAnalyzed_list])\n",
    "    sentimentAnalyzed_concat = np.concatenate(sentimentAnalyzed_array)\n",
    "\n",
    "    sentiment_array = np.array([sentiment_list])\n",
    "    sentiment_concat = np.concatenate(sentiment_array)\n",
    "    \n",
    "    bartSummary_array = np.array([bartSummary_list])\n",
    "    bartSummary_concat = np.concatenate(bartSummary_array)\n",
    "\n",
    "    return_df = (\n",
    "        df[[\"asin_key\",\"reviewText\"]]\n",
    "        .assign(bartUpdated=list(bartUpdated_concat))\n",
    "        .assign(sentimentAnalyzed=list(sentimentAnalyzed_concat))\n",
    "        .assign(sentiment=list(sentiment_concat))\n",
    "        .assign(bartSummary=list(bartSummary_concat))\n",
    "    )\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7064693-cc6d-4631-8fb0-c8a06d1288b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_batch():\n",
    "    path = \"s3a://amzn-customer-reviews-228924278364/sink/amzn-reviews-books/\"\n",
    "    llm_transformed_path = \"s3a://amzn-customer-reviews-228924278364/sink/llm-transformed\"\n",
    "    \n",
    "    #df = spark.read.format(\"delta\").load(path)\n",
    "    df = spark.read.format(\"delta\").load(path)\n",
    "\n",
    "    # Check whether summarized_path exists -- will not exist first time\n",
    "    bucket = \"amzn-customer-reviews-228924278364\"\n",
    "    prefix = \"sink/llm-transformed\"\n",
    "    prefix_exist = checkS3PrefixExist(bucket,prefix)\n",
    "\n",
    "    if checkS3PrefixExist(bucket,prefix) == \"n\":\n",
    "       createS3Prefix(bucket,prefix+\"/\")\n",
    "\n",
    "    # Check if Delta table in summarized_path exists\n",
    "    if DeltaTable.isDeltaTable(spark, llm_transformed_path) == False:\n",
    "        createDeltaSummarizedTable(llm_transformed_path)\n",
    "\n",
    "    # Get main df\n",
    "    df = df.select(\"asin_key\",\"reviewText\").filter((df.bartUpdated == \"N\") & (df.asin_key.isNotNull())).limit(10)\n",
    "\n",
    "    schema = StructType(\n",
    "       [\n",
    "           StructField(\"asin_key\", IntegerType(), True),\n",
    "           StructField(\"reviewText\", StringType(), True),\n",
    "           StructField(\"bartUpdated\", StringType(), True),\n",
    "           StructField(\"sentimentAnalyzed\", StringType(), True),\n",
    "           StructField(\"sentiment\", StringType(), True), \n",
    "           StructField(\"bartSummary\", StringType(), True)\n",
    "       ]\n",
    "    )\n",
    "\n",
    "    df_summary = ( df\n",
    "      .groupBy(spark_partition_id().alias(\"_pid\"))\n",
    "      .applyInPandas(getPdfLLM,schema)\n",
    "    )\n",
    "\n",
    "    #sink_path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-bart-summarized/\"\n",
    "    df_summary.write.format(\"delta\").mode(\"append\").save(llm_transformed_path)\n",
    "\n",
    "    # Update bartUpdated column to \"Y\"\n",
    "    deltaTableMain = DeltaTable.forPath(spark, path)\n",
    "    deltaTableUpdateSource = DeltaTable.forPath(spark, llm_transformed_path)\n",
    "\n",
    "    dfUpdates = deltaTableUpdateSource.toDF()\n",
    "\n",
    "    deltaTableMain.alias('main') \\\n",
    "       .merge(\n",
    "           dfUpdates.alias('updates'),\n",
    "           'main.asin_key = updates.asin_key'\n",
    "       ) \\\n",
    "       .whenMatchedUpdate(set = \n",
    "           {\n",
    "               \"bartUpdated\": \"updates.bartUpdated\",\n",
    "               \"sentimentAnalyzed\": \"updates.sentimentAnalyzed\",\n",
    "               \"sentiment\": \"updates.sentiment\",\n",
    "               \"bartSummary\": \"updates.bartSummary\",\n",
    "           }\n",
    "       ) \\\n",
    "       .execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb974b-d2cd-4674-87c7-f9929f895143",
   "metadata": {},
   "source": [
    "# Run for a few rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2508dab-0531-4324-9f03-b319f1091400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/14 16:56:46 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/03/14 16:56:53 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/03/14 16:56:56 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/14 16:56:56 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/14 16:56:57 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "24/03/14 16:56:57 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore ubuntu@172.31.73.213\n",
      "24/03/14 16:56:57 WARN ObjectStore: Failed to get database delta, returning NoSuchObjectException\n",
      "24/03/14 16:57:10 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "2024-03-14 16:57:13.932302: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-14 16:57:13.932358: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-14 16:57:13.933529: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-14 16:57:13.940245: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-14 16:57:14.651068: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "24/03/14 16:57:28 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/14 16:57:41 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1044 > 512). Running this sequence through the model will result in indexing errors\n",
      "/home/ubuntu/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1157: UserWarning: You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "  warnings.warn(\n",
      "24/03/14 16:57:53 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/14 16:58:06 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (881 > 512). Running this sequence through the model will result in indexing errors\n",
      "24/03/14 16:58:17 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/14 16:58:52 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (709 > 512). Running this sequence through the model will result in indexing errors\n",
      "24/03/14 16:59:02 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/14 16:59:25 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (635 > 512). Running this sequence through the model will result in indexing errors\n",
      "24/03/14 16:59:36 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/14 16:59:39 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n"
     ]
    }
   ],
   "source": [
    "loop = 5\n",
    "for i in range(loop):\n",
    "    llm_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24063bf-b337-4d75-858c-c5fbd0761648",
   "metadata": {},
   "source": [
    "# View Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a841071-3a42-4abe-908d-04e2b31ffab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3a://amzn-customer-reviews-228924278364/sink/amzn-reviews-books/\"\n",
    "llm_transformed_path = \"s3a://amzn-customer-reviews-228924278364/sink/llm-transformed\"\n",
    "df = spark.read.format(\"delta\").load(llm_transformed_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "345c4333-f99a-4ac3-8bf2-cb3f856d90c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin_key: integer (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- bartUpdated: string (nullable = true)\n",
      " |-- sentimentAnalyzed: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- bartSummary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d1430-84bc-446e-b429-7166bc365efb",
   "metadata": {},
   "source": [
    "# Count difference between summarized review and actual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7b78614-5836-41ec-a950-d665167c2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = ( df.select(\"asin_key\",length(df.reviewText).alias(\"lengthText\"),\n",
    "                           length(df.bartSummary).alias(\"lengthBartSummary\"),\"bartSummary\",\n",
    "                ( length(df.reviewText) - length(df.bartSummary) ).alias(\"lengthDiff\"))\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31e67221-7b7a-4a89-9ad2-b15c396ba2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------------+--------------------+----------+\n",
      "| asin_key|lengthText|lengthBartSummary|         bartSummary|lengthDiff|\n",
      "+---------+----------+-----------------+--------------------+----------+\n",
      "|449127982|      4872|             1217|Matt Helm has had...|      3655|\n",
      "|470124172|      3811|              262|The book would be...|      3549|\n",
      "|486253864|      2924|              314|The beautiful clo...|      2610|\n",
      "|671024442|      2606|              307|The End of Everyt...|      2299|\n",
      "|545074584|      2143|              314|Henry's father al...|      1829|\n",
      "|451461444|      1948|              232|There is so much ...|      1716|\n",
      "|446579815|      1992|              299|Christopher Buckl...|      1693|\n",
      "|451461754|      1783|              247|Seattle P.I. Harp...|      1536|\n",
      "|439845092|      1716|              255|Homeschooler's da...|      1461|\n",
      "|385518927|      1563|              197|Being nice builds...|      1366|\n",
      "|385340559|      1567|              230|Bad Luck and Trou...|      1337|\n",
      "|439895766|      1514|              281|The main characte...|      1233|\n",
      "|613734564|      1561|              357|Kaye is not at al...|      1204|\n",
      "|452266637|      1446|              285|Rice included a v...|      1161|\n",
      "|451221001|      1094|              198|The story drags o...|       896|\n",
      "|448095408|      1055|              238|This case for the...|       817|\n",
      "|615188222|      1115|              309|Nancy Douglas is ...|       806|\n",
      "|393017206|      1009|              209|This may be the m...|       800|\n",
      "|465044263|       983|              214|This book is a hi...|       769|\n",
      "|470137320|       983|              260|Marketers need to...|       723|\n",
      "+---------+----------+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_check.sort(df_check.lengthDiff.desc()).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25af6826-7fdd-4d77-b6a3-60dc0c213912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------+-----------------+--------------------+----------+\n",
      "| asin_key|lengthText|lengthBartSummary|         bartSummary|lengthDiff|\n",
      "+---------+----------+-----------------+--------------------+----------+\n",
      "|449127982|      4872|             1217|Matt Helm has had...|      3655|\n",
      "|470124172|      3811|              262|The book would be...|      3549|\n",
      "|486253864|      2924|              314|The beautiful clo...|      2610|\n",
      "|671024442|      2606|              307|The End of Everyt...|      2299|\n",
      "|545074584|      2143|              314|Henry's father al...|      1829|\n",
      "|451461444|      1948|              232|There is so much ...|      1716|\n",
      "|446579815|      1992|              299|Christopher Buckl...|      1693|\n",
      "|451461754|      1783|              247|Seattle P.I. Harp...|      1536|\n",
      "|439845092|      1716|              255|Homeschooler's da...|      1461|\n",
      "|385518927|      1563|              197|Being nice builds...|      1366|\n",
      "|385340559|      1567|              230|Bad Luck and Trou...|      1337|\n",
      "|439895766|      1514|              281|The main characte...|      1233|\n",
      "|613734564|      1561|              357|Kaye is not at al...|      1204|\n",
      "|452266637|      1446|              285|Rice included a v...|      1161|\n",
      "|451221001|      1094|              198|The story drags o...|       896|\n",
      "|448095408|      1055|              238|This case for the...|       817|\n",
      "|615188222|      1115|              309|Nancy Douglas is ...|       806|\n",
      "|393017206|      1009|              209|This may be the m...|       800|\n",
      "|465044263|       983|              214|This book is a hi...|       769|\n",
      "|470137320|       983|              260|Marketers need to...|       723|\n",
      "+---------+----------+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_check.distinct().sort(df_check.lengthDiff.desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3758b3e-d6d7-4ae5-a3bf-d58d888c04e2",
   "metadata": {},
   "source": [
    "# View actual text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1ca376ea-8965-430d-9109-9e0f5638b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view_summary = (\n",
    "    df.filter(\"asin_key==449127982\").distinct()\n",
    "       .select(\"asin_key\",\"reviewText\",\"bartSummary\")\n",
    "       .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898d4c1-a74b-4412-be9d-56182c2b4677",
   "metadata": {},
   "source": [
    "# Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41fc0306-8295-4cf0-98f7-f9fa29bb031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mission Two: The Wrecking Crew\n",
      "Matt Helm series Reviews by Ujjwal Dey\n",
      "\n",
      "Well the first one is beaten to grit and grim by this second one in the series. A little longer at 176 pages, still an easy read for my weekend; this one brings Helm into a whole new line of action in espionage business.\n",
      "\n",
      "Now Matt Helm has had his refresher course in the covert groups training - the American Mordgruppe - The Wrecking Crew - an unknown, unspoken elite group of operatives who generally work alone to do what armies and clouts of bureaucrats can't achieve. The man is just right for the job. The trainers believe he is in no shape to be an operative and certainly past his prime. His bad new resume was certain to get him killed on a field mission. Mac agrees - he is just the man for this job.\n",
      "\n",
      "Matt Helm now has to play dumb; to act like a clumsy ancient World War trooper who can't call the shots in this peacetime covert warfare. As a photographer for an American magazine he lands up in Artic Europe to shoot innocent bland photos of mines for a girl who could be a double-agent or simply a fool in this foolish game. The girl in question has survived a bullet meant for her journalist husband who had the gall to write a tale describing a Russian agent - The Man No one Knows. Of course this deadly Russian operative has no sympathy for such breakthrough journalism, and now the supposed widow is carrying out her husband's journalistic inclinations.\n",
      "\n",
      "There is more than meets the eye and pretty women are lethal in more ways than one. Helm's contact in Sweden is shot dead in the face, double-crossed by her evil mysterious agent. Helm has to contend with getting bruised and bashed around to prove himself harmless to a variety of operatives - biding his time to get his orders.\n",
      "\n",
      "Yes, the men in Washington call off lethal action - no Government ordered assassination during peacetime - but that is not a restriction upon Helm's enemies. Matt Helm goes through unraveling intricacies in the players' cards, as a poker player who has to display ignorance of any known card game. As people show up dead around him, things come to light and when the final game is afoot - Matt has the aces up his sleeve to vindicate Mac's faith in him.\n",
      "\n",
      "The violence is as bad if not worse than the first book - which is a good thing in any gritty espionage thriller. The brief reflections on the first book events such as him carving up an old lady friend and his separation from his wife also come up very much accurately into the new plot. His handiness without a gun is seen very well in this story as essentially he has to go out there unarmed to convincingly play the role of an American photographer, even if the cover doesn't fool his targets.\n",
      "\n",
      "The geographical descriptions and accuracy in detail is wonderful and you can imagine yourself tracing his trail across the mountains and into wilderness in the Arctic. He has to \"make the touch\" - Group M speak for killing the target - similar to what mafia would say \"making a hit\". But he has to be patient enough to identify the mysterious Russian spy, wait for the go ahead from his Boss, and then make sure he does it cleanly - being in a friendly country during peacetime.\n",
      "\n",
      "Putting up a classy display of ineptness, we also get to read about all that he could have done as a master agent but doesn't to keep himself useful to the Russian agent - he is able to prove himself harmless on more than one occasion until finally its time for a showdown.\n",
      "\n",
      "Cars, guns, women's choice of clothes, all again feature in this sequel in Matt Helm's ponderings. There are women he trusts and they assuredly betray him and Helm is not one to be heartbroken or sentimental - he goes about his business with determination and calculation - even surprising his own Government's other operatives (of other departments) - who fall for his \"clumsy\" act. At the end Helm proves himself to be as cunning and ruthless as his Russian rival. The climax action with its cold-blooded moves sees Helm make his touch and save a damsel from distress as well. The last chapter adds more to Helm's personality and legend. His un-emotive demeanour at what could have been a tragic romantic scene ensures he is the man with a job he is good at.\n",
      "\n",
      "If you thought gadgets and expensive machinery with latest guns was the way an agent wins a war - you have watched too many James Bond movies. This book's account shows us in a believable and clinical clarity how a secret agent would go through with his mission in a foreign country. Matt Helm is no great fist-fighter but he knows how to fight and here we see him use more of the matter between his ears in contrast to the trigger in enemy hands.\n",
      "\n",
      "Extract: When you act like a nice guy, everyone examines your motives with a microscope. When you act like a conscienceless louse, they generally take you at face value.\n",
      "\n",
      "****\n"
     ]
    }
   ],
   "source": [
    "print(df_view_summary[0][\"reviewText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290311f-f5c0-48a1-a31b-c5d197a049b8",
   "metadata": {},
   "source": [
    "# Summarized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "751334a4-d1cb-49f9-8178-58170ff78153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matt Helm has had his refresher course in the covert groups training - the American Mordgruppe - The Wrecking Crew. Helm has to contend with getting bruised and bashed around to prove himself harmless to a variety of operatives. The violence is as bad if not worse than the first book - which is a good thing in any gritty espionage thriller. The geographical descriptions and accuracy in detail is wonderful and you can imagine yourself tracing his trail across the mountains and into wilderness in the Arctic. At the end Helm proves himself to be as cunning and ruthless as his Russian rival. If you thought gadgets and expensive machinery with latest guns was the way an agent wins a war - you have watched too many James Bond movies. This book's account shows us in a believable and clinical clarity how a secret agent would go through with his mission in a foreign country. Matt Helm is no great fist-fighter but he knows how to fight and here we see him use more of the matter between his ears in contrast to the trigger in enemy hands. Extract: When you act like a nice guy, everyone examines your motives with a microscope. When you act like a conscienceless louse, they generally take you at face value. ****\n"
     ]
    }
   ],
   "source": [
    "print(df_view_summary[0][\"bartSummary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fcdd46c-068f-41db-b1cb-557fa1f7cbad",
   "metadata": {},
   "source": [
    "# View Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cc5765f5-d7bf-4ad3-b569-5534079201c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment = df.select(\"asin_key\",\"reviewtext\",\"sentiment\")\n",
    "df_main = spark.read.format(\"delta\").load(path)\n",
    "df_main_select = df_main.select(df_main.asin_key.alias(\"asin_key_main\"),\"asin\",\"overall\")\n",
    "df_sentiment_main = df_sentiment.join(\n",
    "    df_main_select,df_sentiment.asin_key == df_main_select.asin_key_main,\n",
    "    \"inner\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ccf2b71-bf0a-4a32-9032-643b4170ebef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin_key: integer (nullable = true)\n",
      " |-- reviewtext: string (nullable = true)\n",
      " |-- sentiment: string (nullable = true)\n",
      " |-- asin_key_main: integer (nullable = true)\n",
      " |-- asin: string (nullable = true)\n",
      " |-- overall: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sentiment_main.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "94234a0b-a228-4123-836c-2b4e7a91a256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+---------+-------------+----------+-------+\n",
      "| asin_key|          reviewtext|sentiment|asin_key_main|      asin|overall|\n",
      "+---------+--------------------+---------+-------------+----------+-------+\n",
      "|380770741|Didn't really car...| negative|    380770741|0380770741|    2.0|\n",
      "|385340559|As you'll begin t...| positive|    385340559|0385340559|    5.0|\n",
      "|385518927|You may not be fa...| positive|    385518927|0385518927|    4.0|\n",
      "|393017206|Update after seco...| positive|    393017206|0393017206|    5.0|\n",
      "|395557011|My son is 2 years...| positive|    395557011|0395557011|    5.0|\n",
      "|415325102|One need not be a...| positive|    415325102|0415325102|    4.0|\n",
      "|425221644|The Red Scarf was...| positive|    425221644|0425221644|    5.0|\n",
      "|439845092|When using the Bo...| positive|    439845092|0439845092|    5.0|\n",
      "|439895766|The premise of th...| negative|    439895766|0439895766|    2.0|\n",
      "|441013651|What makes this b...| positive|    441013651|0441013651|    5.0|\n",
      "+---------+--------------------+---------+-------------+----------+-------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sentiment_main.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e2a47243-05a0-489c-9400-2a5ed71e6b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|sentiment|count|\n",
      "+---------+-----+\n",
      "| positive|15060|\n",
      "| negative| 6451|\n",
      "+---------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_sentiment_main.groupBy(\"sentiment\").count().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e08b87-ca48-4fe3-8529-84795e6d3636",
   "metadata": {},
   "source": [
    "# Looking at a positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c013d236-49e7-4ecd-9125-d74ec71c4481",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sentiment_check = df.select(\"reviewText\").filter(\"asin_key == 385340559\").collect()\n",
    "df_main_check = df_main.select(\"overall\").filter(\"asin_key == 385340559\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "440c736d-b151-4779-b27c-f6133901abdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer indicated score: 5.0\n",
      "======================\n",
      "As you'll begin to see by the books I review here, I have very eclectic taste in books. Some might think the Reacher books by Lee Child are more suited to a male audience, but, hey, this is the era of the kickass girl.\n",
      "\n",
      "As a woman who took karate in Okinawa (decades ago before that was a common thing) with an Army tank of a sensei, I like to think I fit the kickass paradigm. I wholeheartedly enjoy these books so read on. You may find you enjoy them too.\n",
      "\n",
      "If you've ever watched The Unit starring Dennis Haysbert then it's not a great stretch to imagine if The Unit personnel retired and wrote books, the books would be pretty much like a Jack Reacher novel.\n",
      "\n",
      "In Bad Luck and Trouble, members of Reacher's Special Investigators are being killed. The other members ride to the rescue. Reacher and his former team members, notably Frances Neagley whose picture probably resides next to the word kickass in the dictionary, set about making things right and making those responsible pay.\n",
      "\n",
      "I won't give away any spoilers because it really is a neat action book, but with surprisingly mild language from these characters. The action melds well with a mathematical savant element of Reacher's personality. Plus, Lee Child actually writes a good love scene for a male author. Kudos to Mr. Child.\n",
      "\n",
      "All in all, it's like a very good read with buddy humor, good characters, nice suspense, a little shocking violence, and a really good, smart payback.\n",
      "\n",
      "The book made the rounds of my family. Read it, and you too will be waiting for the next Jack Reacher novel from Lee Child.\n"
     ]
    }
   ],
   "source": [
    "checktext = df_sentiment_check[0][\"reviewText\"]\n",
    "checkoverall = df_main_check[0][\"overall\"]\n",
    "print(f\"Customer indicated score: {checkoverall}\")\n",
    "print(\"======================\")\n",
    "print(checktext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239979ca-66c2-4bb9-a4a6-9ad573f0deb3",
   "metadata": {},
   "source": [
    "# Looking at a negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4345af1c-af82-4fe9-9470-1612e6015c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_sentiment_check = df.select(\"reviewText\").filter(\"asin_key == 380770741\").collect()\n",
    "df_main_check = df_main.select(\"overall\").filter(\"asin_key == 380770741\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aef7339d-5f34-4036-a683-4aedd4a3dc28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer indicated score: 2.0\n",
      "======================\n",
      "Didn't really care for this book. I did not like Grace at all, she was without honor. She comes to marry one man for his money and lets another man(not knowing he is the man she is to marry)seduce her after only the second time they had met and so forth. And Arran was no better,knowing Grace was marrying him for his money and was cheating on him (with what Grace thought was another man)(that's what his last wife did to him right;the reason he didn't want to marry again)felt he was falling in love with Grace on the third day. I'm sorry... but what crap! If you like petting and panting after just a few pages, this is the book for you, but if you are like me and like a strong female/male relationship where they actually take some time to know and have respect for each other first, you may want to give this book a pass.\n"
     ]
    }
   ],
   "source": [
    "checktext = df_sentiment_check[0][\"reviewText\"]\n",
    "checkoverall = df_main_check[0][\"overall\"]\n",
    "print(f\"Customer indicated score: {checkoverall}\")\n",
    "print(\"======================\")\n",
    "print(checktext)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307a82e-2d4e-4d11-93b4-cf4949723596",
   "metadata": {},
   "source": [
    "# Check main Delta Tables, BartUpdated column updated to Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9c07a3-9164-43d0-b96c-711d0d9bb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-foreach-pandas/\"\n",
    "    \n",
    "#df = spark.read.format(\"delta\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cd45cfc8-edab-483c-8f1b-18ae0c54213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check_updated = df.select(\"asin_key\",\"bartUpdated\",\"sentimentAnalyzed\").filter((df.bartUpdated == \"Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da44c3fb-d8ee-4276-b51f-d1158e01f701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6f75bafd-9187-4efb-b5d8-7dc75f7e4282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+--------------------+-----------+-----------------+---------+--------------------+\n",
      "| asin_key|          reviewText|bartUpdated|sentimentAnalyzed|sentiment|         bartSummary|\n",
      "+---------+--------------------+-----------+-----------------+---------+--------------------+\n",
      "|446579815|Baby Boomers are ...|          Y|                Y| negative|Christopher Buckl...|\n",
      "|448089181|While the book wa...|          Y|                Y| negative|Chet and Biff, mi...|\n",
      "|448095408|How can you not l...|          Y|                Y| positive|This case for the...|\n",
      "|449127982|Mission Two: The ...|          Y|                Y| negative|Matt Helm has had...|\n",
      "|451221001|Ok, I will admit ...|          Y|                Y| negative|The story drags o...|\n",
      "|451223772|I've read all of ...|          Y|                Y| negative|I've read all of ...|\n",
      "|451224515|This series is ju...|          Y|                Y| positive|This series is ju...|\n",
      "|451412494|<a data-hook=\"pro...|          Y|                Y| negative|The plot and the ...|\n",
      "|451458443|Now we have White...|          Y|                Y| positive|Now we have White...|\n",
      "|451461444|Reviewed by Vicky...|          Y|                Y| positive|There is so much ...|\n",
      "|380770741|Didn't really car...|          Y|                Y| negative|If you like petti...|\n",
      "|385340559|As you'll begin t...|          Y|                Y| positive|Bad Luck and Trou...|\n",
      "|385518927|You may not be fa...|          Y|                Y| positive|Being nice builds...|\n",
      "|393017206|Update after seco...|          Y|                Y| positive|This may be the m...|\n",
      "|395557011|My son is 2 years...|          Y|                Y| positive|My son is 2 years...|\n",
      "|415325102|One need not be a...|          Y|                Y| positive|One need not be a...|\n",
      "|425221644|The Red Scarf was...|          Y|                Y| positive|The Red Scarf was...|\n",
      "|439845092|When using the Bo...|          Y|                Y| positive|Homeschooler's da...|\n",
      "|439895766|The premise of th...|          Y|                Y| negative|The main characte...|\n",
      "|441013651|What makes this b...|          Y|                Y| positive|What makes this b...|\n",
      "+---------+--------------------+-----------+-----------------+---------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
