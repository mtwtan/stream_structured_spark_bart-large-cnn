{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7db1de9a-2561-4bfc-9846-93c076256a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import HiveContext, SparkSession\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.window import Window\n",
    "from delta import *\n",
    "from chunkipy import TextChunker, TokenEstimator\n",
    "import boto3\n",
    "import json\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "581bfd20-b3f9-4432-8320-75d13cafa986",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-12 15:54:57.656023: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 15:54:57.656083: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 15:54:57.657468: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-12 15:54:57.665026: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 15:54:58.472239: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, BertTokenizer, pipeline\n",
    "#tokenizer = BertTokenizer.from_pretrained(\"google-bert/bert-base-uncased\")\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\", framework=\"pt\", device=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32694141-0f90-432c-9d82-5e82d922a1ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/opt/spark-3.5.0-bin-hadoop3/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /home/ubuntu/.ivy2/cache\n",
      "The jars for the packages stored in: /home/ubuntu/.ivy2/jars\n",
      "io.delta#delta-spark_2.12 added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-7a1dff2e-36e7-4555-a7f2-b1b2a48608f1;1.0\n",
      "\tconfs: [default]\n",
      "\tfound io.delta#delta-spark_2.12;3.1.0 in local-m2-cache\n",
      "\tfound io.delta#delta-storage;3.1.0 in local-m2-cache\n",
      "\tfound org.antlr#antlr4-runtime;4.9.3 in local-m2-cache\n",
      ":: resolution report :: resolve 156ms :: artifacts dl 7ms\n",
      "\t:: modules in use:\n",
      "\tio.delta#delta-spark_2.12;3.1.0 from local-m2-cache in [default]\n",
      "\tio.delta#delta-storage;3.1.0 from local-m2-cache in [default]\n",
      "\torg.antlr#antlr4-runtime;4.9.3 from local-m2-cache in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   3   |   0   |   0   |   0   ||   3   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-7a1dff2e-36e7-4555-a7f2-b1b2a48608f1\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 3 already retrieved (0kB/5ms)\n",
      "24/03/12 15:57:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/03/12 15:57:21 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n"
     ]
    }
   ],
   "source": [
    "builder = SparkSession.builder.appName(\"amzn-reviews\") \\\n",
    "    .config(\"spark.sql.extensions\", \"io.delta.sql.DeltaSparkSessionExtension\") \\\n",
    "    .config(\"spark.sql.catalog.spark_catalog\", \"org.apache.spark.sql.delta.catalog.DeltaCatalog\") \\\n",
    "    .config(\"spark.driver.cores\", \"2\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.executor.memory\",\"28g\") \\\n",
    "    .config(\"spark.executor.cores\",\"5\") \\\n",
    "    .config(\"spark.executor.instances\",\"2\") \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.enabled\",True) \\\n",
    "    .config(\"spark.sql.execution.arrow.pyspark.fallback.enabled\", True) \\\n",
    "    .config(\"spark.sql.parquet.mergeSchema\", False) \\\n",
    "    .config(\"spark.hadoop.parquet.enable.summary-metadata\", False) \\\n",
    "    .enableHiveSupport()\n",
    "\n",
    "spark = configure_spark_with_delta_pip(builder).getOrCreate()\n",
    "\n",
    "sc = spark.sparkContext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "425863ee-7725-4656-91cf-90217810897e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get secrets credential for S3a\n",
    "REGION = \"us-east-1\"\n",
    "client = boto3.client('secretsmanager',region_name=REGION)\n",
    "response = client.get_secret_value(\n",
    "    SecretId='s3all'\n",
    ")\n",
    "accessJson = json.loads(response['SecretString'])\n",
    "accessKeyId = accessJson['accessKey']\n",
    "secretAccessKey = accessJson['secretAccess']\n",
    "\n",
    "# Configure S3a\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", accessKeyId)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", secretAccessKey)\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"s3.us-east-1.amazonaws.com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "532fa52b-cd78-4a03-8b39-2462b026bab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertTokenEstimator(TokenEstimator):\n",
    "    def __init__(self):\n",
    "        self.bert_tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "    def estimate_tokens(self, text):\n",
    "        return len(self.bert_tokenizer.encode(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "539f06db-c456-40b5-ba96-7ae0fee0eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkS3PrefixExist(bucket,prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    prefix_exist = \"\"\n",
    "    \n",
    "    try:\n",
    "        resp = s3.head_object(Bucket=bucket, Key=prefix)\n",
    "        prefix_exist = \"y\"\n",
    "    except s3.exceptions.ClientError as e:\n",
    "        if e.response['Error']['Code'] == '404':\n",
    "            prefix_exist = \"n\"\n",
    "        else:\n",
    "            prefix_exist = \"something else\"\n",
    "\n",
    "    return prefix_exist\n",
    "    \n",
    "def createS3Prefix(bucket,prefix):\n",
    "    s3 = boto3.client('s3')\n",
    "    s3.put_object(Bucket=bucket,Key=prefix)\n",
    "\n",
    "def createDeltaSummarizedTable(path):\n",
    "    DeltaTable.createOrReplace(spark) \\\n",
    "     .addColumn(\"asin_key\", \"INT\") \\\n",
    "     .addColumn(\"reviewText\", \"STRING\") \\\n",
    "     .addColumn(\"bartUpdated\", \"STRING\") \\\n",
    "     .addColumn(\"bartSummary\", \"STRING\") \\\n",
    "     .location(path) \\\n",
    "     .execute()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d51553b2-61bc-4a04-a29e-2a82b7fefd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPdfBartSummary(df):\n",
    "    # Variables\n",
    "    max_token_input = 1024\n",
    "    min_token_output = 130\n",
    "    chunk_size = 512\n",
    "    min_token_size = 200\n",
    "    \n",
    "    # Initializing summary to return\n",
    "    summary_text = \"\"\n",
    "    \n",
    "    # Initialize BertEstimator\n",
    "    bert_token_estimator = BertTokenEstimator()\n",
    "\n",
    "    def batchSize(token_count, max_token_input):\n",
    "        quotient = token_count / max_token_input\n",
    "        remainder = token_count % max_token_input\n",
    "        return math.floor(quotient), remainder\n",
    "\n",
    "    def chunk(txt):\n",
    "        token_count = bert_token_estimator.estimate_tokens(txt)\n",
    "        text_chunker = TextChunker(chunk_size, tokens=True, token_estimator=BertTokenEstimator())\n",
    "        chunks = text_chunker.chunk(txt)\n",
    "\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            yield chunk\n",
    "\n",
    "    def summarizer_func(corpus):\n",
    "        summary_response = summarizer(corpus, max_length=130, min_length=30, do_sample=False)\n",
    "        summary = summary_response[0][\"summary_text\"]\n",
    "        return summary\n",
    "        \n",
    "    # Main code\n",
    "    bartUpdated_list = []\n",
    "    bartSummary_list = []\n",
    "    reviewText = [d.reviewText for idx, d in df.iterrows()]\n",
    "    \n",
    "    for r in reviewText:\n",
    " \n",
    "        token_count = bert_token_estimator.estimate_tokens(r)\n",
    "\n",
    "        if token_count > max_token_input:\n",
    "\n",
    "            text_chunker = TextChunker(chunk_size, tokens=True, token_estimator=BertTokenEstimator())\n",
    "            chunks = text_chunker.chunk(r)\n",
    "\n",
    "            corpus_chunks = []\n",
    "            \n",
    "            for i, chunk in enumerate(chunks):\n",
    "                if bert_token_estimator.estimate_tokens(chunk)  <= min_token_size:\n",
    "                    corpus_chunks.append(chunk)\n",
    "                else:\n",
    "                    corpus_chunks.append(summarizer_func(chunk))\n",
    "\n",
    "            s = \" \"\n",
    "            summary_text = s.join(corpus_chunks)\n",
    "            \n",
    "        \n",
    "        else:\n",
    "            if token_count < min_token_output:\n",
    "                summary_text = r\n",
    "            else:\n",
    "                summary_text = summarizer_func(r)\n",
    "            #print(\"small:\", summary_text)\n",
    "        bartUpdated_list.append(\"Y\")\n",
    "        bartSummary_list.append(summary_text)\n",
    "        #print(\"bartsummarylist:\", bartSummary_list)\n",
    "    \n",
    "    bartUpdated_array = np.array([bartUpdated_list])\n",
    "    bartUpdated_concat = np.concatenate(bartUpdated_array)\n",
    "    bartSummary_array = np.array([bartSummary_list])\n",
    "    bartSummary_concat = np.concatenate(bartSummary_array)\n",
    "\n",
    "    return_df = (\n",
    "        df[[\"asin_key\",\"reviewText\"]]\n",
    "        .assign(bartUpdated=list(bartUpdated_concat))\n",
    "        .assign(bartSummary=list(bartSummary_concat))\n",
    "    )\n",
    "    \n",
    "    return return_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e7064693-cc6d-4631-8fb0-c8a06d1288b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_batch():\n",
    "    path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-foreach-pandas/\"\n",
    "    summarized_path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-bart-summarized\"\n",
    "    \n",
    "    #df = spark.read.format(\"delta\").load(path)\n",
    "    df = spark.read.format(\"delta\").load(path)\n",
    "\n",
    "    # Check whether summarized_path exists -- will not exist first time\n",
    "    bucket = \"amzn-customer-reviews-228924278364\"\n",
    "    prefix = \"sink/test/test-streaming-bart-summarized/\"\n",
    "    prefix_exist = checkS3PrefixExist(bucket,prefix)\n",
    "\n",
    "    if checkS3PrefixExist(bucket,prefix) == \"n\":\n",
    "       createS3Prefix(bucket,prefix)\n",
    "\n",
    "    # Check if Delta table in summarized_path exists\n",
    "    if DeltaTable.isDeltaTable(spark, summarized_path) == False:\n",
    "        createDeltaSummarizedTable(summarized_path)\n",
    "\n",
    "    # Get main df\n",
    "    df = df.select(\"asin_key\",\"reviewText\").filter((df.bartUpdated == \"N\") & (df.asin_key.isNotNull())).limit(10)\n",
    "\n",
    "    schema = StructType(\n",
    "       [\n",
    "            StructField(\"asin_key\", IntegerType(), True),\n",
    "            StructField(\"reviewText\", StringType(), True),\n",
    "            StructField(\"bartUpdated\", StringType(), True),\n",
    "            StructField(\"bartSummary\", StringType(), True)\n",
    "       ]\n",
    "    )\n",
    "\n",
    "    df_summary = ( df\n",
    "      .groupBy(spark_partition_id().alias(\"_pid\"))\n",
    "      .applyInPandas(getPdfBartSummary,schema)\n",
    "    )\n",
    "\n",
    "    #sink_path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-bart-summarized/\"\n",
    "    df_summary.write.format(\"delta\").mode(\"append\").save(summarized_path)\n",
    "\n",
    "    # Update bartUpdated column to \"Y\"\n",
    "    deltaTableMain = DeltaTable.forPath(spark, path)\n",
    "    deltaTableUpdateSource = DeltaTable.forPath(spark, summarized_path)\n",
    "\n",
    "    dfUpdates = deltaTableUpdateSource.toDF()\n",
    "\n",
    "    deltaTableMain.alias('main') \\\n",
    "       .merge(\n",
    "           dfUpdates.alias('updates'),\n",
    "           'main.asin_key = updates.asin_key'\n",
    "       ) \\\n",
    "       .whenMatchedUpdate(set = \n",
    "           {\n",
    "               \"bartUpdated\": \"updates.bartUpdated\",\n",
    "               \"bartSummary\": \"updates.bartSummary\",\n",
    "           }\n",
    "       ) \\\n",
    "       .execute()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb974b-d2cd-4674-87c7-f9929f895143",
   "metadata": {},
   "source": [
    "# Run for a few rounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5a370d0a-8b0d-422b-bc2d-3072921a5507",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n\n"
     ]
    }
   ],
   "source": [
    "bucket = \"amzn-customer-reviews-228924278364\"\n",
    "prefix = \"sink/test/test-streaming-bart-summarized/\"\n",
    "print(checkS3PrefixExist(bucket,prefix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2508dab-0531-4324-9f03-b319f1091400",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/12 15:58:51 WARN MetricsConfig: Cannot locate configuration: tried hadoop-metrics2-s3a-file-system.properties,hadoop-metrics2.properties\n",
      "24/03/12 15:58:58 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "24/03/12 15:59:01 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/03/12 15:59:01 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/03/12 15:59:02 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "24/03/12 15:59:02 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore ubuntu@172.31.73.213\n",
      "24/03/12 15:59:02 WARN ObjectStore: Failed to get database delta, returning NoSuchObjectException\n",
      "24/03/12 15:59:14 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "2024-03-12 15:59:18.697524: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-03-12 15:59:18.697581: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-03-12 15:59:18.698761: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-03-12 15:59:18.705432: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-03-12 15:59:19.422512: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
      "24/03/12 15:59:28 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 15:59:40 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 15:59:46 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 15:59:58 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "Token indices sequence length is longer than the specified maximum sequence length for this model (862 > 512). Running this sequence through the model will result in indexing errors\n",
      "24/03/12 16:00:04 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 16:00:16 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 16:00:21 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 16:00:32 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n",
      "24/03/12 16:00:38 WARN ParquetOutputFormat: Setting parquet.enable.summary-metadata is deprecated, please use parquet.summary.metadata.level\n"
     ]
    }
   ],
   "source": [
    "loop = 5\n",
    "for i in range(loop):\n",
    "    summarize_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24063bf-b337-4d75-858c-c5fbd0761648",
   "metadata": {},
   "source": [
    "# View Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a841071-3a42-4abe-908d-04e2b31ffab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-bart-summarized/\"\n",
    "\n",
    "df = spark.read.format(\"delta\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "345c4333-f99a-4ac3-8bf2-cb3f856d90c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- asin_key: integer (nullable = true)\n",
      " |-- reviewText: string (nullable = true)\n",
      " |-- bartUpdated: string (nullable = true)\n",
      " |-- bartSummary: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d0d1430-84bc-446e-b429-7166bc365efb",
   "metadata": {},
   "source": [
    "# Count difference between summarized review and actual review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7b78614-5836-41ec-a950-d665167c2862",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_check = ( df.select(\"asin_key\",length(df.reviewText).alias(\"lengthText\"),\n",
    "                           length(df.bartSummary).alias(\"lengthBartSummary\"),\"bartSummary\",\n",
    "                ( length(df.reviewText) - length(df.bartSummary) ).alias(\"lengthDiff\"))\n",
    "          )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "31e67221-7b7a-4a89-9ad2-b15c396ba2f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+--------------------+----------+\n",
      "|asin_key|lengthText|lengthBartSummary|         bartSummary|lengthDiff|\n",
      "+--------+----------+-----------------+--------------------+----------+\n",
      "| 2247437|      4209|              256|The fourth volume...|      3953|\n",
      "| 7447868|      4209|              256|The fourth volume...|      3953|\n",
      "| 7230206|      1518|              225|Hilary Mantel's n...|      1293|\n",
      "| 7514123|      1206|              250|\"I was so disappo...|       956|\n",
      "|29059909|      1195|              307|Mark Clodfelter's...|       888|\n",
      "| 7436580|       755|              180|Casey Watson's hu...|       575|\n",
      "| 7242638|       777|              220|Wayne Rooney's ne...|       557|\n",
      "| 7181604|       643|              255|This is a typical...|       388|\n",
      "|28811259|       264|              264|Great read and wa...|         0|\n",
      "|14768578|       344|              344|Sorry, but The Bo...|         0|\n",
      "|29201357|        17|               17|   EXCELLENT HISTORY|         0|\n",
      "|14933412|       109|              109|The heroine is st...|         0|\n",
      "|61030082|        23|               23|Great read for th...|         0|\n",
      "|22152867|       125|              125|Excellent continu...|         0|\n",
      "|30554543|       292|              292|This book should ...|         0|\n",
      "|14396038|       154|              154|Great book for th...|         0|\n",
      "|61109086|        38|               38|Book was in good ...|         0|\n",
      "|29537156|        37|               37|You will have to ...|         0|\n",
      "|30680093|       103|              103|A great book!  I ...|         0|\n",
      "| 7503210|        57|               57|Predictable and r...|         0|\n",
      "+--------+----------+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_check.sort(df_check.lengthDiff.desc()).show(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "25af6826-7fdd-4d77-b6a3-60dc0c213912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+-----------------+--------------------+----------+\n",
      "|asin_key|lengthText|lengthBartSummary|         bartSummary|lengthDiff|\n",
      "+--------+----------+-----------------+--------------------+----------+\n",
      "| 7447868|      4209|              256|The fourth volume...|      3953|\n",
      "| 2247437|      4209|              256|The fourth volume...|      3953|\n",
      "| 7230206|      1518|              225|Hilary Mantel's n...|      1293|\n",
      "| 7514123|      1206|              250|\"I was so disappo...|       956|\n",
      "|29059909|      1195|              307|Mark Clodfelter's...|       888|\n",
      "| 7436580|       755|              180|Casey Watson's hu...|       575|\n",
      "| 7242638|       777|              220|Wayne Rooney's ne...|       557|\n",
      "| 7181604|       643|              255|This is a typical...|       388|\n",
      "|59074312|       413|              413|The explosive fir...|         0|\n",
      "|29776996|        23|               23|Great author, goo...|         0|\n",
      "|44305734|        29|               29|Slow start but ex...|         0|\n",
      "|36921445|       319|              319|What a great nove...|         0|\n",
      "|22152867|       125|              125|Excellent continu...|         0|\n",
      "|14888498|       106|              106|If you're a Robin...|         0|\n",
      "|29537156|        37|               37|You will have to ...|         0|\n",
      "|14768578|       344|              344|Sorry, but The Bo...|         0|\n",
      "| 2310015|        67|               67|Christie wrote ma...|         0|\n",
      "| 7173121|        12|               12|        she loves it|         0|\n",
      "| 8488158|        14|               14|      Fantastic read|         0|\n",
      "| 7196997|        29|               29|great series, gre...|         0|\n",
      "+--------+----------+-----------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_check.distinct().sort(df_check.lengthDiff.desc()).show(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3758b3e-d6d7-4ae5-a3bf-d58d888c04e2",
   "metadata": {},
   "source": [
    "# View actual text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1ca376ea-8965-430d-9109-9e0f5638b64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_view_summary = (\n",
    "    df.filter(\"asin_key==7447868\").distinct()\n",
    "       .select(\"asin_key\",\"reviewText\",\"bartSummary\")\n",
    "       .collect()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4898d4c1-a74b-4412-be9d-56182c2b4677",
   "metadata": {},
   "source": [
    "# Original text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "41fc0306-8295-4cf0-98f7-f9fa29bb031a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fourth volume of George R.R. Martins saga, A Song of Fire and Ice, propels the reader down the storyline of what took place in Westeros following the events that took place in A Storm of Swords. This volume and most of the fifth volume feature the storylines running concurrently, but split into the two books. What this portends for the succeeding volumes is unknown, but the fact that Martin needed two books instead of one to advance the saga is a bit unnerving. The volumes are already stretching into the thousand page marks with years between releases.\n",
      "\n",
      " A Feast for Crows does not disappoint the reader though. It is worth every penny of its purchase. The death of Tywin Lannister has thrown the Seven Kingdoms into turmoil. A boy king, his mother who demands to be the regent, the maimed commander of the Kingsguard who resents his sister (and former lover) for her betrayal, unrest among the people as winter comes to the southlands, religious fanaticism taking hold as the crown ignores the people, and the continued shifting of power and alliances fill the pages. Uncertainty abounds with every turn of the page. Are the wars of the five kings over or are they just in a lull period?\n",
      "\n",
      " A new king claims the Iron Islands while another claimant moves south from the Wall. While not featured in this book, it is known that one claimant to the throne still lives in Mereen and she has dragons. Meanwhile, Bran and his party move north following their vision to its conclusion. If anything, this book fills in what could have been major gaps in the plot. While peace lies uneasily in much of the lands, men still maneuver for power as no clear leader seems to be stepping forward to rule the land.\n",
      "\n",
      " I found this volume to be more about character development than others had been. I was particularly impressed with the changes made in Jamie Lannisters character. The loss of his sword hand has made him adapt and begin to use his brain to solve many of the problems he seeks to solve. His use of diplomacy in resolving sieges and ending the last vestiges of the war is particularly interesting.  The introduction of characters from Dorne was an outstanding addition to the saga. It is one of the few untouched areas of Westeros and its might could definitely change the balance of power. Many Dornish seek to use that power immediately, but its leader bides his time waiting for the right moment.\n",
      "\n",
      " Yes, this volume really brings forth the maneuvering in developing powerful alliances which fall apart all the time. While not nearly as deadly for characters as the previous books, the death of minor characters continues as Martin depicts the lands as deadly as ever. The style of writing had remained the same as well. Chapters are brief, and are from one characters point of view per chapter while expanding the saga. The themes remain very adult however. This is not a book for young readers.\n",
      "\n",
      " I really do not want to give any of the plot away. It is clear that Martin has some serious work ahead of him in unifying the plotlines together which will involve more death. Religion is brought to the forefront of this book for the first time in the saga. Before it had existed, but not in a form that carried any real weight. In this book, religious fanaticism rears its head. As we see by current events, this can be a very powerful force in the world. Martin shows how that works within the medieval framework.\n",
      "\n",
      " All in all, this is an excellent book and one that grabs the readers attention. With the HBO series now filming episodes that feature events that take place after what Martin has written so far, it remains unclear how things will develop in the future. Already several storylines have been significantly altered from the books. How Martins chooses to advance the saga will be interesting. One thing is clear. Eventually peace will return to the Seven Kingdoms. The problem will be if no one is left alive to enjoy it. The winter is coming and so is a great evil in the North which may require the humans to band together in order to fight it. Martin seems to be showing how a lack of unity may be too much for humanity to overcome when faced with supernatural death and destruction.\n"
     ]
    }
   ],
   "source": [
    "print(df_view_summary[0][\"reviewText\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290311f-f5c0-48a1-a31b-c5d197a049b8",
   "metadata": {},
   "source": [
    "# Summarized text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "751334a4-d1cb-49f9-8178-58170ff78153",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The fourth volume of George R.R. Martins saga, A Song of Fire and Ice, propels the reader down the storyline of what took place in Westeros. This volume and most of the fifth volume feature the storylines running concurrently, but split into the two books.\n"
     ]
    }
   ],
   "source": [
    "print(df_view_summary[0][\"bartSummary\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0307a82e-2d4e-4d11-93b4-cf4949723596",
   "metadata": {},
   "source": [
    "# Check main Delta Tables, BartUpdated column updated to Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc9c07a3-9164-43d0-b96c-711d0d9bb007",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"s3a://amzn-customer-reviews-228924278364/sink/test/test-streaming-foreach-pandas/\"\n",
    "    \n",
    "df = spark.read.format(\"delta\").load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cd45cfc8-edab-483c-8f1b-18ae0c54213c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.select(\"asin_key\",\"bartUpdated\",\"reviewText\").filter((df.bartUpdated == \"Y\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "da44c3fb-d8ee-4276-b51f-d1158e01f701",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "6f75bafd-9187-4efb-b5d8-7dc75f7e4282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+--------------------+\n",
      "|asin_key|bartUpdated|          reviewText|\n",
      "+--------+-----------+--------------------+\n",
      "| 1844423|          Y|Thank you, it was...|\n",
      "| 2245833|          Y|This was one of m...|\n",
      "| 2310015|          Y|Christie wrote ma...|\n",
      "| 8488158|          Y|      Fantastic read|\n",
      "| 2226162|          Y|    Loved this book.|\n",
      "| 2247437|          Y|The fourth volume...|\n",
      "| 7173121|          Y|        she loves it|\n",
      "| 7181604|          Y|This is a typical...|\n",
      "| 7196997|          Y|great series, gre...|\n",
      "| 7198019|          Y|Beautiful book. N...|\n",
      "|14396038|          Y|Great book for th...|\n",
      "|14426364|          Y|I still have my o...|\n",
      "|21639546|          Y|A waste of money,...|\n",
      "| 7217099|          Y|Great story joini...|\n",
      "| 7230206|          Y|They used to say ...|\n",
      "| 7242476|          Y|I was only a few ...|\n",
      "| 7242638|          Y|I never like Wayn...|\n",
      "| 7350503|          Y|great story well ...|\n",
      "|14701798|          Y|           Wonderful|\n",
      "|14756066|          Y|enjoyed the book,...|\n",
      "|14768578|          Y|Sorry, but The Bo...|\n",
      "|22152867|          Y|Excellent continu...|\n",
      "|29537156|          Y|You will have to ...|\n",
      "|36921445|          Y|What a great nove...|\n",
      "|44305734|          Y|Slow start but ex...|\n",
      "|59074312|          Y|The explosive fir...|\n",
      "| 7436580|          Y|Sad story of a da...|\n",
      "|14888498|          Y|If you're a Robin...|\n",
      "|29776996|          Y|Great author, goo...|\n",
      "| 7447868|          Y|The fourth volume...|\n",
      "|14933412|          Y|The heroine is st...|\n",
      "| 7503210|          Y|Predictable and r...|\n",
      "|15027526|          Y|Bought this book ...|\n",
      "| 7514123|          Y|Dr. Lustig's  you...|\n",
      "| 7547412|          Y|Not as good as Ch...|\n",
      "| 7554850|          Y|book\\n\\nI thoroug...|\n",
      "| 7577605|          Y|I didn't know wha...|\n",
      "| 7697287|          Y|This is a beautif...|\n",
      "|15851130|          Y|Good story, kind ...|\n",
      "|31702260|          Y|One of the only b...|\n",
      "|28811259|          Y|Great read and wa...|\n",
      "|29059909|          Y|Mark Clodfelter's...|\n",
      "|29201357|          Y|   EXCELLENT HISTORY|\n",
      "|61030082|          Y|Great read for th...|\n",
      "|30554543|          Y|This book should ...|\n",
      "|61109086|          Y|Book was in good ...|\n",
      "|30680093|          Y|A great book!  I ...|\n",
      "|60083999|          Y|  Leonard is the man|\n",
      "|60088877|          Y|Reading the old c...|\n",
      "|60156988|          Y|   Very informative.|\n",
      "| 2247437|          Y|I echo what some ...|\n",
      "| 7242476|          Y|It was worth what...|\n",
      "| 7447868|          Y|I echo what some ...|\n",
      "+--------+-----------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97fc6e1-ce11-4048-802b-4c2921ae0cd8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
